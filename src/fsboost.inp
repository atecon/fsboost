function bundle default_fsreg_opts (void)
    /* Set default values */

    bundle self = null
    scalar self.verbose = 1
    string self.early_stopping_strategy = "residual_corr_abs"
    add_early_stopping_threshold(&self)
    scalar self.learning_rate = 0.01
    scalar self.max_num_iterations = 10000
    scalar self.early_stopping_rounds = 50

    return self
end function


function void add_early_stopping_threshold (bundle *self)
    /* Add threshold for early stopping depending on early stopping type. */

    if self.early_stopping_strategy == "residual_corr_abs"
        # Abs. correlation has to improve at minimum by x units.
        scalar self.early_stopping_threshold = 0.01
    elif self.early_stopping_strategy == "residual_corr_rel"
        # Abs. correlation has to improve at minimum relatively by x.
        scalar self.early_stopping_threshold = 0.05
    endif
end function


function void stdize_y_and_x (bundle *self)
    /* Demeaning series y and list X and compute associated std.-errors. */

    matrix self.my = cdemean({self.y}, TRUE)
    scalar self.ysd = sdc({self.y})
    matrix self.mX = cdemean({self.X_wo_constant}, TRUE)
    matrix self.Xsd = sdc({self.X_wo_constant})
end function


function void initialize (bundle *self, const series y, const list X)
    /* Some initalizations. */

    scalar self.T = $nobs
    series self.y = y
    list self.X_wo_constant = X - const
    scalar self.with_constant = nelem(self.X_wo_constant) < nelem(X) ? \
                                TRUE : FALSE
    if self.with_constant == TRUE
        strings self.Xnames_wo_constant = strdrop(self.Xnames, "const")
    else
        strings self.Xnames_wo_constant = self.Xnames
    endif

    # Initializations of variables for estimator function
    scalar self.resid_mean = 0
    matrix self.rho_values = mshape(NA, self.max_num_iterations, 1)
    matrix self.betas = zeros(self.max_num_iterations, nelem(self.X_wo_constant))
    scalar self.actual_num_iterations = NA
end function


function bundle fsreg_gui (const series y "Dep. variable",
                           const list X "Candidates",
                           const scalar learning_rate[0.0001:0.9999:0.025] "Learning rate",
                           int max_num_iterations[100::10000] "Max. number of iterations",
                           int early_stopping_rounds[20::50] "Early stopping rounds",
                           bool plot_coefficient_paths[0] "Plot coefficient paths",
                           bool plot_rho_values[0] "Plot correlation w. residuals",
                           int verbose[0:2:1] "Print details" {"quiet", "details", "more details"})
    /* GUI wrapper for fsreg(). */

    bundle model = null
    scalar model.verbose = verbose
    scalar model.learning_rate = learning_rate
    scalar model.max_num_iterations = max_num_iterations
    scalar model.early_stopping_rounds = early_stopping_rounds

    bundle model = fsreg(y, X, model)
    print_fsboost_results(model)

    if plot_rho_values == TRUE
        plot_rho_values(model)
    endif

    if plot_coefficient_paths == TRUE
        plot_coefficient_paths(model)
    endif

    return model
end function


function bundle fsreg (const series y "Dep. variable",
                       const list X "Candidates",
                       bundle opts[null])

    /* Main function for forward-stagewise boosted regression. */

    if $datatype != 2       # cross-sectional or panel
        smpl --no-missing y X
    else                    # time-series case
        smpl --contiguous y X
    endif

    bundle self = default_fsreg_opts()
    if exists(opts)
        self = opts + self         # override defaults
    endif

    # Initilizations
    string self.yname = argname(y)
    strings self.Xnames = varnames(X)
    initialize(&self, y, X)
    add_early_stopping_threshold(&self)

    stdize_y_and_x(&self)
    fsreg_estimator(&self)
    post_process(&self)

    # Handle intercept: non-scaled as "coeff" is already re-scaled
    matrix resids = {y - lincomb(self.X_wo_constant, self.coeff)}
    if self.with_constant
        scalar self.resid_mean = meanc(resids)
        self.coeff = self.resid_mean | self.coeff
    endif
    matrix self.coeff_nonzero = get_nonzero_rescaled_coeffs(self)

    attach_coefficient_row_labels(&self)

    scalar self.ncoeff = rows(vec(self.coeff_nonzero))

    add_yhat_and_uhat_to_bundle(y, X, &self)

    post_estimation_statistics(&self)

    list self.X_final = add_selected_predictors_to_list(X, self)

    cleanup_bundle(&self)

    return self
end function


function void post_estimation_statistics (bundle *self)
  /* Add post-estimation statistics to return bundle. */

  add_sd_of_uhat(&self)
  add_first_order_residual_corr(&self)
  get_insample_stats(&self)
end function


function void add_sd_of_uhat (bundle *self)
  /* Standard deviation of residuals */

  scalar self.uhat_variance = sd(self.uhat)
end function

function void add_first_order_residual_corr (bundle *self)
  /* First order serial correlation coefficient. */

  if $datatype == 2
    matrix muhat = {self.uhat}
    muhat ~= mlag(muhat, 1)
    scalar self.uhat_first_order_corr = mcorr(muhat)[1,2]
  endif
end function


function list add_selected_predictors_to_list (const list X, const bundle self)
    /* Add active set of predictors to list. */

    list L = (self.with_constant == TRUE) ? const : null
    S = get_names_of_nonzero_coeffs(self)

    loop foreach i S
        list L += genseries("$i", X.$i)
    endloop

    return L
end function


function void add_yhat_and_uhat_to_bundle (const series y,
                                           const list X,
                                           bundle *self)
    /* Add final fitted values and residuals to bundle. */

    series self.yhat = lincomb(X, self.coeff)
    series self.uhat = y - self.yhat
end function


function void get_insample_stats (bundle *self)
    /* Collect insample statistics of fit. */

    # from regls pkg.
    matrix stats = regls_get_stats(self.y, self.yhat)
    pos_mse = instrings(cnameget(stats), "MSE")
    pos_r2 = instrings(cnameget(stats), "R^2")
    self.r2 = stats[pos_r2]
    self.mse = stats[pos_mse]

    # from ridge pkg
    matrix r_squares = r2_stats(self.my, {self.yhat}, self.ncoeff)
    scalar self.r2_qcorr = r_squares[1]
end function


/*
function void get_insample_stats (bundle *self)
    #Wrapper calling functions for computing R^2.
    #Function r2_stats() is taken from the "ridge" package.
    #TODO: Currently, we only know that stuff is statistically applicable for statistics "r2_qcorr".

    scalar self.r2_qcorr = NA

    matrix r_squares = r2_stats(self.my, {self.yhat}, self.ncoeff)
    scalar self.r2_qcorr = r_squares[1]
    scalar self.r2 = get_rsquare(self)
    #scalar self.r2_qcorr_adj = r_squares[2]          # depends on self.ncoeff
    #scalar self.r2_scores = r_squares[3]
end function
*/


/*
function scalar get_rsquare (const bundle self)
    # Alternative computation of R-squared statistics.

    return 1 - sum((self.y - self.yhat)^2) / sst(self.y)
end function
*/

function void cleanup_bundle (bundle *self)
    /* Drop unnecessary stuff from bundle */

    delete self.Xsd
    delete self.ysd
    delete self.mX
    delete self.y
    delete self.my
    #delete self.ncoeff
    delete self.X_wo_constant
    delete self.resid_mean
end function


function void attach_coefficient_row_labels (bundle *self)
    /* Attach row labels to vector of point estimates. */

    strings S = array(0)

    S = (self.with_constant == TRUE) ? defarray("const") : S
    strings S += get_names_of_nonzero_coeffs(self)
    rnameset(self.coeff_nonzero, S)
    rnameset(self.coeff, self.Xnames)
end function


function void post_process (bundle *self)
    /* Wrapper for some post-processing. */

    get_valid_rho_values(&self)
    cumsum_coefficient_paths(&self)
    matrix self.coeff = get_rescaled_coeffs(self)
end function


function void cumsum_coefficient_paths (bundle *self)
    /* Cumulate iterative coefficient estimates, restrict vector length and attach column labels for each regressor (needed for optional plotting. */

    self.betas = cum(self.betas[1:self.actual_num_iterations,])
    cnameset(self.betas, self.Xnames_wo_constant)
end function


function void get_valid_rho_values (bundle *self)
    /* Restrict vector to length equal to the number of actual iterations. */
    self.rho_values = self.rho_values[1:self.actual_num_iterations]
end function


function matrix get_rescaled_coeffs (const bundle self)
    /* Retrieve all final point estimates and rescale. */

    return self.betas[self.actual_num_iterations,]' .* (self.ysd ./ self.Xsd')
end function


function matrix get_nonzero_rescaled_coeffs (const bundle self)
    /* Retrieve final non-zero point estimates. */

    matrix bhat_all = self.coeff
    matrix mask = (self.coeff .!= 0)

    return selifr(self.coeff, mask)
end function


function scalar get_max_correlation (const matrix yX,
                                     scalar *position "j-th regressor")
    /* Compute correlations between "y" and all exogenous variables ("X").
     Return maximum of absolute correlations. */

    scalar k = cols(yX) - 1
    matrix correlations = mshape(NA, k, 1)

    loop i=1..k
        correlations[i] = mcorr(yX[,1] ~ yX[,1+i])[1,2]
    endloop
    scalar position = imaxc(abs(correlations))

    return correlations[position]
end function


function void print_early_stopping_reached (const bundle self)
    /* Print info message on early stopping*/

    if self.verbose > 0
        printf "\nInfo: No improvement in score '%s' for\n\
                the last %d iterations.\nEarly stopping applies.\n",\
                self.early_stopping_strategy, self.early_stopping_rounds
    endif
end function


function void print_iteration_details (const bundle self,
                                       int iteration,
                                       const scalar rho "Correlation coeff.")
    /* */

    if self.verbose == 2
        printf "\nInfo: Iteration %d out of %d: correlation coeff. = %g.\n", iteration, self.max_num_iterations, rho
    endif
end function


function scalar early_stopping_applies (const bundle self,
                                        const scalar score_former,
                                        const scalar score_current)
    /* Decision whether the early stopping criteria is met, or not.
     return: If the criteria is met, return TRUE, otherwise FALSE. */

    if self.early_stopping_strategy == "residual_corr_abs"
        scalar delta = abs(score_former) - abs(score_current)
    elif self.early_stopping_strategy == "residual_corr_rel"
        scalar delta = ( abs(score_former) - abs(score_current) ) / \
                        abs(score_former)
    endif

    if delta < 0    # correlation increased
        return TRUE
    else
        return (delta >= self.early_stopping_threshold) ? FALSE : TRUE
    endif
end function


function void fsreg_estimator (bundle *self)
    /* Actual implementation of the boosting-like forward stagewise algorithm. */

    matrix yX = self.my ~ self.mX

    scalar n_rounds_no_improvement = 0
    scalar rho_value_former = NA
    scalar self.actual_num_iterations = 0

    loop i=1..self.max_num_iterations
        scalar position = NA
        self.actual_num_iterations++
        scalar col = (i > 1) ? (i-1) : 1

        self.rho_values[i] = get_max_correlation(yX, &position)
        print_iteration_details(self, $i, self.rho_values[i])
        delta = self.learning_rate * sgn(self.rho_values[i])

        # update beta and residuals
        self.betas[i, position] = self.betas[i, position] + delta
        yX[,1] = yX[,1] - delta * self.mX[, position]

        if i > 1    # early stopping
            check = early_stopping_applies(self, self.rho_values[i-1],\
                                            self.rho_values[i])
            if check == TRUE
                n_rounds_no_improvement++
            else
                n_rounds_no_improvement = 0  # reset
            endif
        endif

        if n_rounds_no_improvement == self.early_stopping_rounds
            print_early_stopping_reached(self)
            break
        endif
    endloop
end function


function void plot_coefficient_paths (bundle self,
                                      string filename[null] "Path + filename to store figure",
                                      bool ylog_scale[0])
    /* Plot coefficient paths. */

    string title = "Forward stagewise coefficient paths"
    string ylabel = (ylog_scale == FALSE) ? "Standardized coefficients" : "Standardized coefficients (in logarithms)"
    scalar fontsize = 12
    string filename = (exists(filename)) ? filename : "display"
    string ylog_scale_str = (ylog_scale == TRUE) ? "--ylogscale=10" : ""
    strings names_X_final = strdrop(varnames(self.X_final), "const")
    matrix mplot = get_columns_by_name(self.betas, names_X_final)

    string linestyles = ""
    loop i=1..cols(mplot)
      linestyles += sprintf("set style line %d ps 0.02\n", $i)
    endloop

    set force_decpoint on
    plot mplot
        options with-lp time-series single-yaxis @ylog_scale_str
        printf "@linestyles"
        literal set key right outside
        literal set grid
        printf "set title \"%s\" font \", %d\"", title, fontsize
        printf "set xlabel 'Iterations' font \", %d\"", fontsize
        printf "set ylabel '%s' font \", %d\"", ylabel, fontsize
        printf "set yrange[%g:%g]", min(mplot)*1.1, max(mplot)*1.1
    end plot --output="@filename"
    set force_decpoint off
end function


function matrix get_columns_by_name (const matrix m,
                                     const strings select)
    /* Retrieve columns of 'm' as identified by 'select'. If 'm' has no column labels or 'select' is empty, return empty matrix.
    return: matrix*/

    matrix ret
    strings labels_matrix = cnameget(m)
    if !nelem(labels_matrix) || !nelem(select)
        print "WARNING: No columns selected."
        return ret
    endif

    loop foreach i select
        scalar pos = instrings(labels_matrix, "$i")
        if pos
            ret ~= m[,pos]
        endif
    endloop

    if cols(ret)
        cnameset(ret, select)
    endif

    return ret
end function


function void plot_rho_values (bundle self,
                               string filename[null] "Path + filename to store figure",
                               bool absolute_values[1])
    /* Plot correlation coefficients. */

    string title = "Forward stagewise correlation values"
    string ylabel = (absolute_values == FALSE) ? "Correlations w. residuals" : "Absolute correlations w. residuals"
    scalar fontsize = 12
    string filename = (exists(filename)) ? filename : "display"
    matrix mplot = (absolute_values == TRUE) ? abs(self.rho_values) : self.rho_values

    set force_decpoint on
    plot mplot
        options with-lines time-series
        literal set linetype 1 lc rgb "black" lw 1
        literal set nokey
        literal set grid
        printf "set title \"%s\" font \", %d\"", title, fontsize
        printf "set xlabel 'Iterations' font \", %d\"", fontsize
        printf "set ylabel '%s' font \", %d\"", ylabel, fontsize
    end plot --output="@filename"
    set force_decpoint off
end function


function strings get_names_of_nonzero_coeffs (const bundle self)
    /* Retrieve names variables for which point estimates are non-zero for optimal number of iterations. */

    matrix bhat_all = vec(self.betas[self.actual_num_iterations,])
    scalar n_nonzero_vars = sum(bhat_all .!= 0)
    strings selected_vars = array(n_nonzero_vars)
    scalar counter = 1

    loop i = 1..rows(bhat_all)
        if bhat_all[i] != 0
            selected_vars[counter] = self.Xnames_wo_constant[i]
            counter++
        endif
    endloop

    return selected_vars
end function


function void print_fsboost_results (bundle self)
    /* Print results. */

    printf "\n-------------------------------------------------------\n"
    printf "Forward-stagewise regression results (no inference)\n"
    printf "Early stopping strategy: '%s' (c = %g)",\
            self.early_stopping_strategy, self.early_stopping_threshold
    printf "\n-------------------------------------------------------"

    strings label_str = array(0)

    if self.with_constant
      label_str += defarray("const")
    endif
    label_str += get_names_of_nonzero_coeffs(self)
    label_str += defarray(\
                            "Learning rate",\
                            "Number of iterations",\
                            "Correl. w. residuals",\
                            "S.E. of regression"\
                        )

    matrix extra = self.learning_rate | self.actual_num_iterations |self.rho_values[self.actual_num_iterations] | sd(self.uhat)

    if ok(self.r2)
      matrix extra |= self.r2
      label_str += defarray("R-squared")
    endif
    if ok(self.r2_qcorr)
      matrix extra |= self.r2_qcorr
      label_str += defarray("R-squared alt.")
    endif
    if ok(self.mse)
      matrix extra |= self.mse
      label_str += defarray("MSE")
    endif
    if inbundle(self, "uhat_first_order_corr")
      matrix extra |= self.uhat_first_order_corr
      label_str += defarray("rho")
    endif

    matrix bhat = self.coeff_nonzero ~ NA

    modprint bhat label_str extra
end function


function matrix fsboost_predict (const list L "List of regressors",
                                 const bundle self)
  /* Compute predictions using point estimates. List "L" must comprise the same regressors in the same order as originally passed to fsreg(). */

  matrix pred = {NA}
  list X = null
  matrix bhat = vec(self.coeff)

  if self.with_constant == TRUE && inlist(L, "const") == FALSE
    X += const
  endif
  X += L

  if nelem(X) != rows(bhat)
    printf "\nError: Length of list L does not match originally passed list.\n"
    return pred
  endif

  return lincomb(X, bhat)
end function



function matrix r2_stats (matrix y_true "T by 1 vector of realizations",
                          matrix y_pred "T by 1 vector of estimated values",
                          scalar num_parameters "No. of parameters")
    /* Helper function for computing different R-square statistics. */

    matrix y_true = vec(y_true)
    matrix y_pred = vec(y_pred)

    if rows(y_true) != rows(y_pred)
        printf "\nError: Vectors y_true and y_pred are of different length.\n"
        return NA
    endif
    if rows(y_pred) < 2
        printf "\nError: R^2 score not well-defined with less than two samples.\n"
        return NA
    endif
    if isconst(y_true)
        printf "\nError: Vector y_true is constant.\n"
        return NA
    endif

    matrix R = NA * zeros(3,1)
    R[1] = r2_qcorr(&y_true, &y_pred)
    R[2] = r2_qcorr_adjusted(R[1], rows(y_true), num_parameters)
    R[3] = r2_score(y_true, y_pred)
    rnameset(R, "r2_qcorr r2_qcorr_adj r2_score")

    return R
end function


function scalar r2_qcorr (const matrix *y_true,
                          const matrix *y_pred)
    /* R-square based on quadratic correlation. */
    return corr(y_true, y_pred)^2
end function


function scalar r2_qcorr_adjusted (scalar r2 "R-square from r2_qcorr()",
      int n "Sample length",
      scalar num_parameters "No. of ridge parameters used")
    /* Adjusted R-square based on quadratic correlation */

    nominator = n - 1
    denominator = n - num_parameters - 1

    return 1 - (1-r2) * nominator/denominator
end function


function scalar r2_score (const matrix y_true,
                          const matrix y_pred "Must incl. an intercept if present")
    /* R^2 (coefficient of determination) regression score function.
       Best possible score is 1.0 and it can be negative (because the
       model can be arbitrarily worse). A constant model that always
       predicts the expected value of y, disregarding the input features,
       would get a R^2 score of 0.0.

       Notes
       -----
       This is not a symmetric function.
       Unlike most other scores, R^2 score may be negative (it need not
       actually be the square of a quantity R).
       This metric is not well-defined for single samples and will return
       a NaN value if n_samples is less than two.
       References
       ----------
       <https://github.com/scikit-learn/scikit-learn/blob/
       1495f69242646d239d89a5713982946b8ffcf9d9/
       sklearn/metrics/regression.py#L449>

       `Wikipedia entry on the Coefficient of determination
       <https://en.wikipedia.org/wiki/Coefficient_of_determination>`
    */

    # Initialize check values
    nonzero_denominator = 0
    nonzero_numerator = 0
    valid_score = 0

    # Compute statistics
    scalar numerator = sumc( (y_true-y_pred).^2)
    scalar denominator = sumc( (y_true-mean(y_true)).^2 )

    nonzero_denominator = (denominator != 0) ? 1 : nonzero_denominator
    nonzero_numerator = (numerator!=0) ? 1 : nonzero_numerator

    valid_score = (nonzero_denominator && nonzero_numerator) ? 1 : valid_score

    output_scores = 1

    return (valid_score) ? (1 - numerator/denominator) : output_scores
end function
